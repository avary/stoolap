package mvcc

import (
	"context"
	"encoding/binary"
	"fmt"
	"io"
	"math"
	"os"
	"path/filepath"
	"runtime"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"github.com/semihalev/stoolap/internal/storage"
	"github.com/semihalev/stoolap/internal/storage/binser"
)

// Snapshotter manages the creation, loading, and cleanup of table snapshots
type Snapshotter struct {
	// Engine reference for table access
	engine *MVCCEngine

	// Base directory for all snapshots
	snapshotDir string

	// Snapshot configuration
	interval  time.Duration // Time between snapshots
	keepCount int           // How many snapshots to keep per table

	// Control fields
	running atomic.Bool
	ctx     context.Context
	cancel  context.CancelFunc // Context cancellation function
	wg      sync.WaitGroup     // WaitGroup for active snapshots
}

// TableMetadata stores information about a snapshot
type TableMetadata struct {
	TableName     string
	SchemaHash    uint64
	ColumnCount   int
	RowCount      int
	CreatedAt     time.Time
	FormatVersion uint32
	IndexCount    int      // Number of columnar indexes
	IndexData     [][]byte // Serialized metadata for each columnar index
}

// SchemaFileHeader is written at the beginning of each snapshot file
var SchemaFileHeader = [16]byte{
	// Magic bytes "STLP" (4 bytes)
	'S', 'T', 'L', 'P',
	// Version (4 bytes - uint32 little endian)
	1, 0, 0, 0,
	// Reserved (8 bytes - zero-filled)
	0, 0, 0, 0, 0, 0, 0, 0,
}

// Start begins the snapshot process
func (s *Snapshotter) Start() {
	// Use atomic operation to ensure visibility across goroutines
	if !s.running.CompareAndSwap(false, true) {
		// Already running
		return
	}

	// Create cancellable context for clean shutdown
	s.ctx, s.cancel = context.WithCancel(context.Background())
	s.wg.Add(1)

	// Start the snapshot loop in a goroutine
	go s.run()
}

// Stop halts the snapshotter in a clean, reliable way
func (s *Snapshotter) Stop() {
	// Check if running using atomic operation for thread safety
	if !s.running.CompareAndSwap(true, false) {
		// Not running, nothing to do
		return
	}

	// Cancel the context to signal all operations to stop
	if s.cancel != nil {
		s.cancel()
	}

	// Wait for the snapshot loop to exit with timeout
	waitCh := make(chan struct{})
	go func() {
		s.wg.Wait()
		close(waitCh)
	}()

	// Wait with a reasonable timeout
	select {
	case <-waitCh:
	case <-time.After(DefaultSnapshotLockTimeout):
		// Timeout - log a warning but continue
		fmt.Printf("Warning: Snapshotter stop timed out after %v\n", DefaultSnapshotLockTimeout)
	}
}

// run is the main loop that takes periodic snapshots
func (s *Snapshotter) run() {
	defer s.wg.Done()

	ticker := time.NewTicker(s.interval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			// Take snapshots on each tick
			if err := s.TakeSnapshot(); err != nil {
				fmt.Printf("Error: taking snapshot: %v\n", err)
			}
		case <-s.ctx.Done():
			// Exit when context is canceled
			return
		}
	}
}

// TakeSnapshot creates snapshots of all tables in parallel
func (s *Snapshotter) TakeSnapshot() error {
	// Skip if we're not running
	if !s.running.Load() {
		return nil
	}

	// Get a list of tables to snapshot
	var tableNames []string

	// Always acquire the engine lock when reading the schemas
	s.engine.mu.RLock()
	for tableName := range s.engine.schemas {
		tableNames = append(tableNames, tableName)
	}
	s.engine.mu.RUnlock()

	// Skip if no tables or if we've been asked to stop
	if len(tableNames) == 0 || !s.running.Load() {
		return nil
	}

	// Create a root context with timeout for all snapshot operations
	rootCtx, rootCancel := context.WithTimeout(s.ctx, DefaultSnapshotIOTimeout*3)
	defer rootCancel()

	// Determine number of worker threads (max 1 thread per table, up to CPU count)
	numWorkers := runtime.NumCPU()
	if numWorkers > len(tableNames) {
		numWorkers = len(tableNames)
	}

	// Create a worker pool
	workerPool := NewWorkerPool(numWorkers)
	workerPool.Start()
	defer workerPool.Stop()

	// Progress tracking
	tracker := NewProgressTracker(len(tableNames))

	// Submit snapshot jobs for each table
	for _, tableName := range tableNames {
		// Skip if we've been asked to stop
		if !s.running.Load() {
			return nil
		}

		// Create a job for this table
		job := NewTableSnapshotJob(s, tableName, rootCtx)
		workerPool.Submit(job)
	}

	// Track results
	tablesSnapshotted := 0
	failedTables := make(map[string]error)

	// Collect results as they complete
	for i := 0; i < len(tableNames); i++ {
		select {
		case result := <-workerPool.Results():
			tableName, ok := result.Output.(string)
			if !ok {
				tableName = result.JobID
			}

			if result.Error != nil {
				fmt.Printf("Error: snapshotting table %s: %v\n", tableName, result.Error)
				failedTables[tableName] = result.Error
			} else {
				tablesSnapshotted++
			}

			// Update progress
			tracker.IncreaseCompleted()
			tracker.PrintProgress("Taking Snapshots")

		case <-rootCtx.Done():
			// Overall timeout
			fmt.Printf("Warning snapshot operation timed out after %v\n", DefaultSnapshotIOTimeout*3)
			return rootCtx.Err()
		}
	}

	// Only create a checkpoint after ALL tables have been successfully snapshotted
	// This ensures database-wide consistency of the checkpoint
	if tablesSnapshotted > 0 && s.engine.persistence != nil && s.engine.persistence.wal != nil {
		// Get the current LSN from the WAL
		currentLSN := s.engine.persistence.wal.currentLSN.Load()

		// Create the checkpoint with the current LSN
		s.engine.persistence.wal.createConsistentCheckpoint(currentLSN, true)

		// Update persistence metadata with the snapshot information
		s.engine.persistence.meta.lastWALLSN.Store(currentLSN)
		s.engine.persistence.meta.lastSnapshotLSN.Store(currentLSN)
		s.engine.persistence.meta.lastSnapshotTimeNano.Store(time.Now().UnixNano())

		// Truncate the WAL file using the checkpoint LSN
		// This removes entries that are already captured in the snapshot
		err := s.engine.persistence.wal.TruncateWAL(currentLSN)
		if err != nil {
			fmt.Printf("Warning: Failed to truncate WAL after checkpoint: %v\n", err)
			// Continue despite error since this is not critical
		}
	}

	return nil
}

// snapshotTable creates a snapshot of a single table
func (s *Snapshotter) snapshotTable(ctx context.Context, tableName string) error {
	// Get the version store for this table
	vs, err := s.engine.GetVersionStore(tableName)
	if err != nil {
		return fmt.Errorf("failed to get version store: %w", err)
	}

	// Skip if the version store is closed
	if vs.closed.Load() {
		return nil
	}

	// Get the schema
	schema, err := vs.GetTableSchema()
	if err != nil {
		return fmt.Errorf("failed to get schema: %w", err)
	}

	// Create snapshot directory
	tablePath := filepath.Join(s.snapshotDir, tableName)
	if err := os.MkdirAll(tablePath, 0755); err != nil {
		return fmt.Errorf("failed to create snapshot directory: %w", err)
	}

	// Create snapshot files
	timestamp := time.Now().Format("20060102-150405.000")
	snapshotPath := filepath.Join(tablePath, fmt.Sprintf("snapshot-%s.bin", timestamp))
	metaPath := filepath.Join(tablePath, fmt.Sprintf("snapshot-%s.meta", timestamp))

	// Open files
	file, err := os.Create(snapshotPath)
	if err != nil {
		return fmt.Errorf("failed to create snapshot file: %w", err)
	}

	// Use defer with named return to ensure files are closed
	closeFile := true
	defer func() {
		if closeFile {
			file.Close()
		}
	}()

	metaFile, err := os.Create(metaPath)
	if err != nil {
		return fmt.Errorf("failed to create metadata file: %w", err)
	}

	closeMetaFile := true
	defer func() {
		if closeMetaFile {
			metaFile.Close()
		}
	}()

	// Write schema to file
	if err := s.writeSchema(file, schema); err != nil {
		return fmt.Errorf("failed to write schema: %w", err)
	}

	// Write batch size
	batchSize := 1000
	if err := binary.Write(file, binary.LittleEndian, uint32(batchSize)); err != nil {
		return fmt.Errorf("failed to write batch size: %w", err)
	}

	// Track rows processed
	rowCount := 0
	rowBatch := make([]int64, 0, batchSize)
	dataBatch := make([][]byte, 0, batchSize)
	batchCount := 0

	// Process rows in batches
	// Use a read-only view of the versions to avoid blocking concurrent operations
	vs.versions.ForEach(func(rowID int64, versionPtr *RowVersion) bool {
		// Check for context cancellation
		select {
		case <-ctx.Done():
			return false
		default:
			// Continue processing
		}

		// Skip deleted or empty rows
		if versionPtr.IsDeleted || versionPtr.Data == nil {
			return true
		}

		// Serialize the row
		rowData, err := s.serializeRow(versionPtr.Data)
		if err != nil {
			fmt.Printf("Error: serializing row %d: %v\n", rowID, err)
			return true
		}

		// Add to batch
		rowBatch = append(rowBatch, rowID)
		dataBatch = append(dataBatch, rowData)

		// Write batch if full
		if len(rowBatch) >= batchSize {
			if err := s.writeBatch(file, rowBatch, dataBatch); err != nil {
				fmt.Printf("Error: writing batch: %v\n", err)
				return false
			}

			rowCount += len(rowBatch)
			batchCount++

			// Clear batches
			rowBatch = rowBatch[:0]
			dataBatch = dataBatch[:0]
		}

		return true
	})

	// Check if the context was canceled during the ForEach
	select {
	case <-ctx.Done():
		return ctx.Err()
	default:
		// Continue processing
	}

	// Write final batch if any
	if len(rowBatch) > 0 {
		if err := s.writeBatch(file, rowBatch, dataBatch); err != nil {
			return fmt.Errorf("failed to write final batch: %w", err)
		}

		rowCount += len(rowBatch)
		batchCount++
	}

	// Write end marker
	if err := binary.Write(file, binary.LittleEndian, uint32(0)); err != nil {
		return fmt.Errorf("failed to write end marker: %w", err)
	}

	// Create metadata
	meta := TableMetadata{
		TableName:     tableName,
		SchemaHash:    schemaHash(schema),
		ColumnCount:   len(schema.Columns),
		RowCount:      rowCount,
		CreatedAt:     time.Now(),
		FormatVersion: SchemaVersion,
		IndexData:     make([][]byte, 0),
	}

	// If the version store has columnar indexes, serialize their metadata
	// This is the ONLY place we save index metadata - in the TableMetadata
	if vs != nil {
		// Get all indexes from the version store
		vs.columnarMutex.RLock()
		indexes := make([]storage.Index, 0, len(vs.columnarIndexes))
		for _, idx := range vs.columnarIndexes {
			indexes = append(indexes, idx)
		}
		vs.columnarMutex.RUnlock()

		// Process each index
		for _, idx := range indexes {
			if columnarIdx, ok := idx.(*ColumnarIndex); ok {
				// Serialize index metadata
				indexData, err := SerializeIndexMetadata(columnarIdx)
				if err != nil {
					fmt.Printf("Warning: Failed to serialize index %s: %v\n", columnarIdx.name, err)
					continue
				}
				meta.IndexData = append(meta.IndexData, indexData)
				meta.IndexCount++
			}
		}
	}

	// Write metadata
	if err := s.writeMetadata(metaFile, meta); err != nil {
		return fmt.Errorf("failed to write metadata: %w", err)
	}

	// Force sync to ensure data is on disk
	if err := file.Sync(); err != nil {
		return fmt.Errorf("failed to sync snapshot file: %w", err)
	}

	if err := metaFile.Sync(); err != nil {
		return fmt.Errorf("failed to sync metadata file: %w", err)
	}

	// Close files explicitly to ensure they're properly closed before cleanup
	if err := file.Close(); err != nil {
		return fmt.Errorf("failed to close snapshot file: %w", err)
	}
	closeFile = false

	if err := metaFile.Close(); err != nil {
		return fmt.Errorf("failed to close metadata file: %w", err)
	}
	closeMetaFile = false

	// Clean up old snapshots
	if err := s.cleanupOldSnapshots(tableName, s.keepCount); err != nil {
		// Just log the error but continue - this isn't critical
		fmt.Printf("Warning: Error cleaning up old snapshots: %v\n", err)
	}

	return nil
}

// writeBatch writes a batch of rows to the snapshot file
func (s *Snapshotter) writeBatch(file *os.File, rowIDs []int64, rowData [][]byte) error {
	// Write batch marker
	if err := binary.Write(file, binary.LittleEndian, uint32(len(rowIDs))); err != nil {
		return err
	}

	// Write each row
	for i, id := range rowIDs {
		// Write row ID
		if err := binary.Write(file, binary.LittleEndian, id); err != nil {
			return err
		}

		// Write data length
		if err := binary.Write(file, binary.LittleEndian, uint32(len(rowData[i]))); err != nil {
			return err
		}

		// Write data
		if _, err := file.Write(rowData[i]); err != nil {
			return err
		}
	}

	return nil
}

// writeSchema writes the schema to the snapshot file
func (s *Snapshotter) writeSchema(file *os.File, schemaArg interface{}) error {
	var schema storage.Schema

	// Handle schema being either a pointer or value
	switch s := schemaArg.(type) {
	case storage.Schema:
		schema = s
	case *storage.Schema:
		if s != nil {
			schema = *s
		} else {
			return fmt.Errorf("nil schema")
		}
	default:
		return fmt.Errorf("invalid schema type: %T", schemaArg)
	}

	// Write header
	if _, err := file.Write(SchemaFileHeader[:]); err != nil {
		return fmt.Errorf("failed to write schema header: %w", err)
	}

	// Create a buffer for the schema data
	buf := &strings.Builder{}

	// Write table name
	if err := binary.Write(buf, binary.LittleEndian, uint16(len(schema.TableName))); err != nil {
		return fmt.Errorf("failed to write table name length: %w", err)
	}
	buf.WriteString(schema.TableName)

	// Write column count
	if err := binary.Write(buf, binary.LittleEndian, uint16(len(schema.Columns))); err != nil {
		return fmt.Errorf("failed to write column count: %w", err)
	}

	// Write columns
	for _, col := range schema.Columns {
		// Write column name
		if err := binary.Write(buf, binary.LittleEndian, uint16(len(col.Name))); err != nil {
			return fmt.Errorf("failed to write column name length: %w", err)
		}
		buf.WriteString(col.Name)

		// Write type, nullable, and primary key flags
		buf.WriteByte(byte(col.Type))
		if col.Nullable {
			buf.WriteByte(1)
		} else {
			buf.WriteByte(0)
		}

		if col.PrimaryKey {
			buf.WriteByte(1)
		} else {
			buf.WriteByte(0)
		}
	}

	// Write the buffer to file
	_, err := file.WriteString(buf.String())
	if err != nil {
		return fmt.Errorf("failed to write schema to file: %w", err)
	}

	return nil
}

// serializeRow serializes a row to binary format
func (s *Snapshotter) serializeRow(row storage.Row) ([]byte, error) {
	buf := make([]byte, 0, 256) // Initial buffer size

	// Add column count
	buf = append(buf, byte(len(row)>>8), byte(len(row)))

	// Add each column
	for _, col := range row {
		if col == nil || col.IsNull() {
			// Write NULL marker
			buf = append(buf, binser.TypeNull)
			continue
		}

		// Write the column type
		buf = append(buf, binser.TypeUint8)
		buf = append(buf, byte(col.Type()))

		// Write value based on type
		switch col.Type() {
		case storage.TypeInteger:
			v, _ := col.AsInt64()
			buf = append(buf, binser.TypeInt64)
			// Allocate space for the int64 value
			buf = append(buf, 0, 0, 0, 0, 0, 0, 0, 0)
			// Write directly to the buffer at the correct position
			binary.LittleEndian.PutUint64(buf[len(buf)-8:], uint64(v))

		case storage.TypeFloat:
			v, _ := col.AsFloat64()
			buf = append(buf, binser.TypeFloat64)
			// Allocate space for the float64 value
			buf = append(buf, 0, 0, 0, 0, 0, 0, 0, 0)
			// Write directly to the buffer at the correct position
			binary.LittleEndian.PutUint64(buf[len(buf)-8:], math.Float64bits(v))

		case storage.TypeString:
			v, _ := col.AsString()
			buf = append(buf, binser.TypeString)
			// Allocate space for string length (uint32)
			buf = append(buf, 0, 0, 0, 0)
			// Write the length
			binary.LittleEndian.PutUint32(buf[len(buf)-4:], uint32(len(v)))
			// Append the string data
			buf = append(buf, v...)

		case storage.TypeBoolean:
			v, _ := col.AsBoolean()
			buf = append(buf, binser.TypeBool)
			if v {
				buf = append(buf, 1)
			} else {
				buf = append(buf, 0)
			}

		case storage.TypeTimestamp:
			v, _ := col.AsTimestamp()
			buf = append(buf, binser.TypeTime)
			// Allocate space for the time value (int64 nanoseconds)
			buf = append(buf, 0, 0, 0, 0, 0, 0, 0, 0)
			// Write directly to the buffer at the correct position
			binary.LittleEndian.PutUint64(buf[len(buf)-8:], uint64(v.UnixNano()))

		case storage.TypeDate:
			v, _ := col.AsDate()
			buf = append(buf, binser.TypeTime)
			// Allocate space for the date value (int64 nanoseconds)
			buf = append(buf, 0, 0, 0, 0, 0, 0, 0, 0)
			// Write directly to the buffer at the correct position
			binary.LittleEndian.PutUint64(buf[len(buf)-8:], uint64(v.UnixNano()))

		case storage.TypeTime:
			v, _ := col.AsTime()
			buf = append(buf, binser.TypeTime)
			// Allocate space for the time value (int64 nanoseconds)
			buf = append(buf, 0, 0, 0, 0, 0, 0, 0, 0)
			// Write directly to the buffer at the correct position
			binary.LittleEndian.PutUint64(buf[len(buf)-8:], uint64(v.UnixNano()))

		case storage.TypeJSON:
			v, _ := col.AsJSON()
			buf = append(buf, binser.TypeString)
			// Allocate space for JSON string length (uint32)
			buf = append(buf, 0, 0, 0, 0)
			// Write the length
			binary.LittleEndian.PutUint32(buf[len(buf)-4:], uint32(len(v)))
			// Append the JSON string data
			buf = append(buf, v...)

		default:
			return nil, fmt.Errorf("unsupported type: %v", col.Type())
		}
	}

	return buf, nil
}

// writeMetadata writes the metadata to a file
func (s *Snapshotter) writeMetadata(file io.Writer, meta TableMetadata) error {
	buf := make([]byte, 256) // Initial buffer size
	pos := 0

	// Write format version
	binary.LittleEndian.PutUint32(buf[pos:], meta.FormatVersion)
	pos += 4

	// Write table name
	nameLen := len(meta.TableName)
	binary.LittleEndian.PutUint16(buf[pos:], uint16(nameLen))
	pos += 2

	// Ensure buffer is large enough for the table name
	if pos+nameLen > len(buf) {
		newBuf := make([]byte, pos+nameLen+256)
		copy(newBuf, buf)
		buf = newBuf
	}

	copy(buf[pos:], meta.TableName)
	pos += nameLen

	// Write schema hash
	binary.LittleEndian.PutUint64(buf[pos:], meta.SchemaHash)
	pos += 8

	// Write column count
	binary.LittleEndian.PutUint32(buf[pos:], uint32(meta.ColumnCount))
	pos += 4

	// Write row count
	binary.LittleEndian.PutUint32(buf[pos:], uint32(meta.RowCount))
	pos += 4

	// Write timestamp
	binary.LittleEndian.PutUint64(buf[pos:], uint64(meta.CreatedAt.UnixNano()))
	pos += 8

	// Write index count
	binary.LittleEndian.PutUint32(buf[pos:], uint32(meta.IndexCount))
	pos += 4

	// Write to file the buffer so far
	_, err := file.Write(buf[:pos])
	if err != nil {
		return fmt.Errorf("failed to write metadata header: %w", err)
	}

	// If we have index data, write it separately
	if meta.IndexCount > 0 && len(meta.IndexData) > 0 {
		// For each index, write its data size followed by the data
		for _, indexData := range meta.IndexData {
			// Create a buffer for the index data length
			lenBuf := make([]byte, 4)
			binary.LittleEndian.PutUint32(lenBuf, uint32(len(indexData)))

			// Write the length
			_, err := file.Write(lenBuf)
			if err != nil {
				return fmt.Errorf("failed to write index data length: %w", err)
			}

			// Write the index data
			_, err = file.Write(indexData)
			if err != nil {
				return fmt.Errorf("failed to write index data: %w", err)
			}
		}
	}

	return nil
}

// cleanupOldSnapshots removes old snapshots, keeping the n most recent
func (s *Snapshotter) cleanupOldSnapshots(tableName string, keepCount int) error {
	// Get list of snapshots for this table
	tablePath := filepath.Join(s.snapshotDir, tableName)

	// Verify directory exists before cleanup
	dirInfo, _ := os.Stat(tablePath)
	if dirInfo == nil {
		return nil
	}

	entries, err := os.ReadDir(tablePath)
	if err != nil {
		if os.IsNotExist(err) {
			return nil
		}
		return fmt.Errorf("failed to read snapshot directory: %w", err)
	}

	// Filter and sort snapshots
	var snapshots []string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasPrefix(entry.Name(), "snapshot-") && strings.HasSuffix(entry.Name(), ".bin") {
			snapshots = append(snapshots, entry.Name())
		}
	}

	// Sort by name (which includes timestamp)
	sort.Strings(snapshots)

	// Keep only the most recent n
	if len(snapshots) <= keepCount {
		return nil
	}

	// Remove older snapshots
	for i := 0; i < len(snapshots)-keepCount; i++ {
		binPath := filepath.Join(tablePath, snapshots[i])

		if err := os.Remove(binPath); err != nil {
			// Log error but continue with other files
			fmt.Printf("Warning: failed to remove old snapshot %s: %v\n", binPath, err)
			continue
		}

		// Also remove corresponding metadata file
		metaPath := strings.TrimSuffix(binPath, ".bin") + ".meta"

		if err := os.Remove(metaPath); err != nil {
			// Just log the error but continue
			fmt.Printf("Warning: failed to remove old snapshot metadata %s: %v\n", metaPath, err)
		}
	}

	return nil
}

// findLatestSnapshot finds the most recent snapshot for a table
func (s *Snapshotter) findLatestSnapshot(tableName string) (string, error) {
	// Get list of snapshots for this table
	tablePath := filepath.Join(s.snapshotDir, tableName)
	entries, err := os.ReadDir(tablePath)
	if err != nil {
		if os.IsNotExist(err) {
			return "", nil
		}
		return "", fmt.Errorf("failed to read snapshot directory: %w", err)
	}

	// Filter and sort snapshots
	var snapshots []string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasPrefix(entry.Name(), "snapshot-") && strings.HasSuffix(entry.Name(), ".bin") {
			snapshots = append(snapshots, entry.Name())
		}
	}

	// Sort by name (which includes timestamp)
	sort.Strings(snapshots)

	// Return most recent
	if len(snapshots) > 0 {
		latestSnapshot := snapshots[len(snapshots)-1]
		return latestSnapshot, nil
	}

	return "", nil
}

// loadSnapshot loads a snapshot for a table
func (s *Snapshotter) loadSnapshot(tableName, snapshotFile string) (*storage.Schema, error) {
	// Create a context with timeout for the loading operation
	ctx, cancel := context.WithTimeout(context.Background(), DefaultSnapshotIOTimeout)
	defer cancel()

	// Open snapshot file
	binPath := filepath.Join(s.snapshotDir, tableName, snapshotFile)

	// Verify file exists and is valid
	if err := s.verifySnapshotFile(tableName, snapshotFile); err != nil {
		return nil, fmt.Errorf("invalid snapshot file: %w", err)
	}

	file, err := os.Open(binPath)
	if err != nil {
		return nil, fmt.Errorf("failed to open snapshot file: %w", err)
	}
	defer file.Close()

	// Also open the metadata file
	metaPath := strings.TrimSuffix(binPath, ".bin") + ".meta"
	metaFile, err := os.Open(metaPath)
	if err != nil {
		return nil, fmt.Errorf("failed to open metadata file: %w", err)
	}
	defer metaFile.Close()

	// Read metadata
	meta, err := s.loadMetadata(metaFile)
	if err != nil {
		return nil, fmt.Errorf("failed to read metadata: %w", err)
	}

	// Verify table name
	if meta.TableName != tableName {
		return nil, fmt.Errorf("table name mismatch: expected %s, got %s", tableName, meta.TableName)
	}

	// Read the schema
	schema, err := s.readSchema(file)
	if err != nil {
		return nil, fmt.Errorf("failed to read schema: %w", err)
	}

	// Set the table name
	schema.TableName = tableName

	// Verify schema hash
	calculatedHash := schemaHash(*schema)
	if calculatedHash != meta.SchemaHash {
		return nil, fmt.Errorf("schema hash mismatch: expected %v, got %v", meta.SchemaHash, calculatedHash)
	}

	// Check if we need to load data
	if meta.RowCount == 0 {
		return schema, nil
	}

	// Create or get the table's version store
	vs, err := s.prepareVersionStore(tableName, schema)
	if err != nil {
		return nil, fmt.Errorf("failed to prepare version store: %w", err)
	}

	// Reset file position for data reading
	if _, err := file.Seek(0, io.SeekStart); err != nil {
		return nil, fmt.Errorf("failed to rewind file: %w", err)
	}

	// Load data with context for cancellation/timeout
	if err := s.loadSnapshotData(ctx, file, vs); err != nil {
		return nil, fmt.Errorf("failed to load data: %w", err)
	}

	// Process indexes in parallel if we have multiple indexes
	if meta.IndexCount > 0 && len(meta.IndexData) > 0 {
		// Prepare index metadata first
		var indexesToBuild []*ColumnarIndex
		loadedIndexes := make(map[string]bool)

		// First pass: deserialize all index metadata and create index objects
		for i, indexData := range meta.IndexData {
			// Deserialize the index metadata
			indexMeta, err := DeserializeIndexMetadata(indexData)
			if err != nil {
				fmt.Printf("Warning: Failed to deserialize index metadata %d: %v\n", i, err)
				continue
			}

			// Ensure index name matches table name
			if indexMeta.TableName != tableName {
				fmt.Printf("Warning: Index %s belongs to table %s but is being loaded into %s, skipping\n",
					indexMeta.Name, indexMeta.TableName, tableName)
				continue
			}

			// Track that we've loaded this index
			loadedIndexes[indexMeta.Name] = true

			// Create a new columnar index
			index := NewColumnarIndex(
				indexMeta.Name,
				tableName,
				indexMeta.ColumnName,
				indexMeta.ColumnID,
				indexMeta.DataType,
				vs,
				indexMeta.IsUnique,
			)

			// Set additional properties
			index.isPrimaryKey = indexMeta.IsPrimaryKey

			// Configure time bucketing if enabled
			if indexMeta.EnableTimeBucketing {
				index.EnableTimeBucketing(indexMeta.TimeGranularity)
			}

			// Add to the list of indexes to build
			indexesToBuild = append(indexesToBuild, index)
		}

		// Determine if we should use parallel building
		if len(indexesToBuild) > 1 {
			// Use parallel building for multiple indexes
			buildCtx, buildCancel := context.WithTimeout(ctx, DefaultSnapshotIOTimeout)
			defer buildCancel()

			// Create worker pool with up to CPU count workers, but no more than the number of indexes
			numWorkers := runtime.NumCPU()
			if numWorkers > len(indexesToBuild) {
				numWorkers = len(indexesToBuild)
			}

			workerPool := NewWorkerPool(numWorkers)
			workerPool.Start()
			defer workerPool.Stop()

			// Create progress tracker
			tracker := NewProgressTracker(len(indexesToBuild))

			// Submit index building jobs
			for _, index := range indexesToBuild {
				description := fmt.Sprintf("index-%s-%s", tableName, index.name)
				job := NewIndexBuildJob(index, tracker, description)
				workerPool.Submit(job)
			}

			// Process results
			successCount := 0
			failedIndexes := make(map[string]error)

			// Wait for all indexes to complete building
			for i := 0; i < len(indexesToBuild); i++ {
				select {
				case result := <-workerPool.Results():
					indexName, ok := result.Output.(string)
					if !ok {
						indexName = result.JobID
					}

					if result.Error != nil {
						failedIndexes[indexName] = result.Error
						fmt.Printf("Warning: Failed to build index %s: %v\n", indexName, result.Error)
					} else {
						successCount++

						// Find the corresponding index object
						for _, index := range indexesToBuild {
							if index.name == indexName {
								// Add to version store
								if err := vs.AddIndex(index); err != nil {
									fmt.Printf("Warning: Failed to add index %s to version store: %v\n", indexName, err)
								}
								break
							}
						}
					}

				case <-buildCtx.Done():
					return nil, fmt.Errorf("index building timed out after %v", DefaultSnapshotIOTimeout)
				}
			}
		} else {
			// Sequential building for a single index
			for _, index := range indexesToBuild {
				// Build the index by scanning the data
				if err := index.Build(); err != nil {
					fmt.Printf("Warning: Failed to build index %s: %v\n", index.name, err)
					continue
				}

				// Add the index to the version store
				if err := vs.AddIndex(index); err != nil {
					fmt.Printf("Warning: Failed to add index %s to version store: %v\n", index.name, err)
					continue
				}
			}
		}
	}

	return schema, nil
}

// readSchema reads the schema from a snapshot file
func (s *Snapshotter) readSchema(file io.Reader) (*storage.Schema, error) {
	// Read the header
	header := make([]byte, SchemaHeaderSize)
	if _, err := io.ReadFull(file, header); err != nil {
		return nil, fmt.Errorf("failed to read header: %w", err)
	}

	// Verify magic bytes
	if header[0] != 'S' || header[1] != 'T' || header[2] != 'L' || header[3] != 'P' {
		return nil, fmt.Errorf("invalid magic bytes in header")
	}

	// Verify version
	version := header[4]
	if version != SchemaVersion {
		return nil, fmt.Errorf("unsupported schema version: %d", version)
	}

	// Read table name length
	var nameLen uint16
	if err := binary.Read(file, binary.LittleEndian, &nameLen); err != nil {
		return nil, fmt.Errorf("failed to read table name length: %w", err)
	}

	// Read table name
	nameBytes := make([]byte, nameLen)
	if _, err := io.ReadFull(file, nameBytes); err != nil {
		return nil, fmt.Errorf("failed to read table name: %w", err)
	}
	tableName := string(nameBytes)

	// Read column count
	var colCount uint16
	if err := binary.Read(file, binary.LittleEndian, &colCount); err != nil {
		return nil, fmt.Errorf("failed to read column count: %w", err)
	}

	// Create schema
	schema := &storage.Schema{
		TableName: tableName,
		Columns:   make([]storage.SchemaColumn, colCount),
	}

	// Read each column
	for i := 0; i < int(colCount); i++ {
		// Read column name length
		var colNameLen uint16
		if err := binary.Read(file, binary.LittleEndian, &colNameLen); err != nil {
			return nil, fmt.Errorf("failed to read column name length for column %d: %w", i, err)
		}

		// Read column name
		colNameBytes := make([]byte, colNameLen)
		if _, err := io.ReadFull(file, colNameBytes); err != nil {
			return nil, fmt.Errorf("failed to read column name for column %d: %w", i, err)
		}

		// Read column type
		var colType byte
		typeBytes := make([]byte, 1)
		if _, err := io.ReadFull(file, typeBytes); err != nil {
			return nil, fmt.Errorf("failed to read column type for column %d: %w", i, err)
		}
		colType = typeBytes[0]

		// Read nullable flag
		var nullable byte
		nullableBytes := make([]byte, 1)
		if _, err := io.ReadFull(file, nullableBytes); err != nil {
			return nil, fmt.Errorf("failed to read nullable flag for column %d: %w", i, err)
		}
		nullable = nullableBytes[0]

		// Read primary key flag
		var pk byte
		pkBytes := make([]byte, 1)
		if _, err := io.ReadFull(file, pkBytes); err != nil {
			return nil, fmt.Errorf("failed to read primary key flag for column %d: %w", i, err)
		}
		pk = pkBytes[0]

		// Add column to schema
		schema.Columns[i] = storage.SchemaColumn{
			ID:         i,
			Name:       string(colNameBytes),
			Type:       storage.DataType(colType),
			Nullable:   nullable != 0,
			PrimaryKey: pk != 0,
		}
	}

	return schema, nil
}

// loadMetadata loads metadata from a file
func (s *Snapshotter) loadMetadata(file io.Reader) (TableMetadata, error) {
	var meta TableMetadata

	// Read format version
	if err := binary.Read(file, binary.LittleEndian, &meta.FormatVersion); err != nil {
		return meta, fmt.Errorf("failed to read format version: %w", err)
	}

	// Read table name length
	var nameLen uint16
	if err := binary.Read(file, binary.LittleEndian, &nameLen); err != nil {
		return meta, fmt.Errorf("failed to read table name length: %w", err)
	}

	// Read table name
	nameBytes := make([]byte, nameLen)
	if _, err := io.ReadFull(file, nameBytes); err != nil {
		return meta, fmt.Errorf("failed to read table name: %w", err)
	}
	meta.TableName = string(nameBytes)

	// Read schema hash
	if err := binary.Read(file, binary.LittleEndian, &meta.SchemaHash); err != nil {
		return meta, fmt.Errorf("failed to read schema hash: %w", err)
	}

	// Read column count
	var colCount uint32
	if err := binary.Read(file, binary.LittleEndian, &colCount); err != nil {
		return meta, fmt.Errorf("failed to read column count: %w", err)
	}
	meta.ColumnCount = int(colCount)

	// Read row count
	var rowCount uint32
	if err := binary.Read(file, binary.LittleEndian, &rowCount); err != nil {
		return meta, fmt.Errorf("failed to read row count: %w", err)
	}
	meta.RowCount = int(rowCount)

	// Read timestamp
	var timestamp uint64
	if err := binary.Read(file, binary.LittleEndian, &timestamp); err != nil {
		return meta, fmt.Errorf("failed to read timestamp: %w", err)
	}
	meta.CreatedAt = time.Unix(0, int64(timestamp))

	var indexCount uint32
	if err := binary.Read(file, binary.LittleEndian, &indexCount); err != nil {
		meta.IndexCount = 0
		meta.IndexData = make([][]byte, 0)
		return meta, nil
	}

	meta.IndexCount = int(indexCount)

	// If we have indices, read their data
	if meta.IndexCount > 0 {
		meta.IndexData = make([][]byte, meta.IndexCount)

		for i := 0; i < meta.IndexCount; i++ {
			// Read index data length
			var dataLen uint32
			if err := binary.Read(file, binary.LittleEndian, &dataLen); err != nil {
				return meta, fmt.Errorf("failed to read index data length for index %d: %w", i, err)
			}

			// Read index data
			indexData := make([]byte, dataLen)
			if _, err := io.ReadFull(file, indexData); err != nil {
				return meta, fmt.Errorf("failed to read index data for index %d: %w", i, err)
			}

			meta.IndexData[i] = indexData
		}
	} else {
		meta.IndexData = make([][]byte, 0)
	}

	return meta, nil
}

// prepareVersionStore gets or creates a version store for the table
func (s *Snapshotter) prepareVersionStore(tableName string, schema *storage.Schema) (*VersionStore, error) {
	// Check if table exists
	tableExists, err := s.engine.TableExists(tableName)
	if err != nil {
		return nil, fmt.Errorf("error checking if table exists: %w", err)
	}

	// Create table if it doesn't exist
	if !tableExists {
		_, err = s.engine.CreateTable(*schema)
		if err != nil && err != storage.ErrTableAlreadyExists {
			return nil, fmt.Errorf("error creating table: %w", err)
		}
	}

	// Get version store
	vs, err := s.engine.GetVersionStore(tableName)
	if err != nil {
		return nil, fmt.Errorf("error getting version store: %w", err)
	}

	return vs, nil
}

// loadSnapshotData loads data from a snapshot file into a version store
func (s *Snapshotter) loadSnapshotData(ctx context.Context, file io.ReadSeeker, vs *VersionStore) error {
	// Reset to the beginning of the file
	if _, err := file.Seek(0, io.SeekStart); err != nil {
		return fmt.Errorf("failed to seek to start of file: %w", err)
	}

	// Skip past the header
	header := make([]byte, SchemaHeaderSize)
	if _, err := io.ReadFull(file, header); err != nil {
		return fmt.Errorf("failed to read header: %w", err)
	}

	// Verify magic bytes
	if header[0] != 'S' || header[1] != 'T' || header[2] != 'L' || header[3] != 'P' {
		return fmt.Errorf("invalid magic bytes in header")
	}

	// Read table name length
	var nameLen uint16
	if err := binary.Read(file, binary.LittleEndian, &nameLen); err != nil {
		return fmt.Errorf("failed to read table name length: %w", err)
	}

	// Skip table name
	if _, err := io.CopyN(io.Discard, file, int64(nameLen)); err != nil {
		return fmt.Errorf("failed to skip table name: %w", err)
	}

	// Read column count
	var colCount uint16
	if err := binary.Read(file, binary.LittleEndian, &colCount); err != nil {
		return fmt.Errorf("failed to read column count: %w", err)
	}

	// Skip each column definition
	for i := 0; i < int(colCount); i++ {
		// Skip column name length
		var colNameLen uint16
		if err := binary.Read(file, binary.LittleEndian, &colNameLen); err != nil {
			return fmt.Errorf("failed to read column name length for column %d: %w", i, err)
		}

		// Skip column name
		if _, err := io.CopyN(io.Discard, file, int64(colNameLen)); err != nil {
			return fmt.Errorf("failed to skip column name for column %d: %w", i, err)
		}

		// Skip column type, nullable, and primary key flags (3 bytes)
		if _, err := io.CopyN(io.Discard, file, 3); err != nil {
			return fmt.Errorf("failed to skip column attributes for column %d: %w", i, err)
		}
	}

	// Read batch size
	var batchSize uint32
	if err := binary.Read(file, binary.LittleEndian, &batchSize); err != nil {
		return fmt.Errorf("failed to read batch size: %w", err)
	}

	// Process batches
	rowsLoaded := 0

	for {
		// Check for context cancellation
		select {
		case <-ctx.Done():
			return ctx.Err()
		default:
			// Continue processing
		}

		// Read batch size
		var count uint32
		if err := binary.Read(file, binary.LittleEndian, &count); err != nil {
			if err == io.EOF {
				break
			}
			return fmt.Errorf("failed to read batch count: %w", err)
		}

		// Zero count indicates end of file
		if count == 0 {
			break
		}

		// Process each row in the batch
		for i := uint32(0); i < count; i++ {
			// Check for context cancellation periodically
			if i%100 == 0 {
				select {
				case <-ctx.Done():
					return ctx.Err()
				default:
					// Continue processing
				}
			}

			// Read row ID
			var rowID int64
			if err := binary.Read(file, binary.LittleEndian, &rowID); err != nil {
				return fmt.Errorf("failed to read row ID: %w", err)
			}

			// Read data length
			var dataLen uint32
			if err := binary.Read(file, binary.LittleEndian, &dataLen); err != nil {
				return fmt.Errorf("failed to read data length: %w", err)
			}

			// Read row data - handle very large rows safely
			if dataLen > 100*1024*1024 { // 100MB safety limit
				return fmt.Errorf("row data too large (%d bytes), possible corruption", dataLen)
			}

			data := make([]byte, dataLen)
			if _, err := io.ReadFull(file, data); err != nil {
				return fmt.Errorf("failed to read row data: %w", err)
			}

			// Deserialize row
			row, err := s.deserializeRow(data)
			if err != nil {
				// Log error but continue with next row
				fmt.Printf("Warning: Error deserializing row %d: %v\n", rowID, err)
				continue
			}

			// Add to version store
			vs.AddVersion(rowID, RowVersion{
				TxnID:      -1, // Special transaction ID for snapshot data
				IsDeleted:  false,
				Data:       row,
				RowID:      rowID,
				CreateTime: time.Now().UnixNano(),
			})

			rowsLoaded++
		}
	}

	return nil
}

// deserializeRow deserializes row data
// serializeSchema serializes a table schema for storage in the WAL
func (s *Snapshotter) serializeSchema(schema *storage.Schema) ([]byte, error) {
	// Create a buffer
	buffer := make([]byte, 0, 1024) // Pre-allocate a reasonable size for schema

	// Write schema format version (uint32)
	pos := len(buffer)
	buffer = append(buffer, 0, 0, 0, 0)
	binary.LittleEndian.PutUint32(buffer[pos:], SchemaVersion)

	// Write table name length
	nameLen := len(schema.TableName)
	buffer = append(buffer, byte(nameLen>>8), byte(nameLen))

	// Write table name
	buffer = append(buffer, schema.TableName...)

	// Write number of columns (uint16)
	buffer = append(buffer, byte(len(schema.Columns)>>8), byte(len(schema.Columns)))

	// Write each column
	for _, col := range schema.Columns {
		// Write column ID (uint16)
		buffer = append(buffer, byte(col.ID>>8), byte(col.ID))

		// Write column name length
		nameLen = len(col.Name)

		// Ensure buffer is large enough for the column name
		buffer = append(buffer, byte(nameLen>>8), byte(nameLen))

		// Write column name
		buffer = append(buffer, col.Name...)

		// Write column type
		buffer = append(buffer, byte(col.Type))

		// Write flags (nullable, primary key)
		var flags byte
		if col.Nullable {
			flags |= 1
		}
		if col.PrimaryKey {
			flags |= 2
		}
		buffer = append(buffer, flags)
	}

	// Write timestamps
	// CreatedAt
	pos = len(buffer)
	buffer = append(buffer, 0, 0, 0, 0, 0, 0, 0, 0)
	binary.LittleEndian.PutUint64(buffer[pos:], uint64(schema.CreatedAt.UnixNano()))

	// UpdatedAt
	pos = len(buffer)
	buffer = append(buffer, 0, 0, 0, 0, 0, 0, 0, 0)
	binary.LittleEndian.PutUint64(buffer[pos:], uint64(schema.UpdatedAt.UnixNano()))

	return buffer, nil
}

// deserializeSchema deserializes schema data from binary format
func (s *Snapshotter) deserializeSchema(data []byte) (*storage.Schema, error) {
	if len(data) < 8 {
		return nil, fmt.Errorf("invalid schema data: too short")
	}

	// Create a new schema object
	schema := &storage.Schema{}
	pos := 0

	// Read schema format version
	version := binary.LittleEndian.Uint32(data[pos:])
	pos += 4

	if version != SchemaVersion {
		return nil, fmt.Errorf("unsupported schema format version: %d", version)
	}

	// Read table name length
	if pos+2 > len(data) {
		return nil, fmt.Errorf("unexpected end of data while reading table name length")
	}
	nameLen := int(uint16(data[pos])<<8 | uint16(data[pos+1]))
	pos += 2

	// Read table name
	if pos+nameLen > len(data) {
		return nil, fmt.Errorf("unexpected end of data while reading table name")
	}
	schema.TableName = string(data[pos : pos+nameLen])
	pos += nameLen

	// Read number of columns
	if pos+2 > len(data) {
		return nil, fmt.Errorf("unexpected end of data while reading column count")
	}
	colCount := int(uint16(data[pos])<<8 | uint16(data[pos+1]))
	pos += 2

	// Allocate columns slice
	schema.Columns = make([]storage.SchemaColumn, colCount)

	// Read each column
	for i := 0; i < colCount; i++ {
		// Read column ID
		if pos+2 > len(data) {
			return nil, fmt.Errorf("unexpected end of data while reading column ID")
		}
		colID := int(uint16(data[pos])<<8 | uint16(data[pos+1]))
		pos += 2

		// Read column name length
		if pos+2 > len(data) {
			return nil, fmt.Errorf("unexpected end of data while reading column name length")
		}
		nameLen := int(uint16(data[pos])<<8 | uint16(data[pos+1]))
		pos += 2

		// Read column name
		if pos+nameLen > len(data) {
			return nil, fmt.Errorf("unexpected end of data while reading column name")
		}
		colName := string(data[pos : pos+nameLen])
		pos += nameLen

		// Read column type
		if pos+1 > len(data) {
			return nil, fmt.Errorf("unexpected end of data while reading column type")
		}
		colType := storage.DataType(data[pos])
		pos++

		// Read flags
		if pos+1 > len(data) {
			return nil, fmt.Errorf("unexpected end of data while reading column flags")
		}
		flags := data[pos]
		pos++

		// Parse flags
		nullable := (flags & 1) != 0
		primaryKey := (flags & 2) != 0

		// Create column
		schema.Columns[i] = storage.SchemaColumn{
			ID:         colID,
			Name:       colName,
			Type:       colType,
			Nullable:   nullable,
			PrimaryKey: primaryKey,
		}
	}

	// Read timestamps if there's enough data
	if pos+16 <= len(data) {
		// Read CreatedAt timestamp
		createdAt := binary.LittleEndian.Uint64(data[pos:])
		schema.CreatedAt = time.Unix(0, int64(createdAt))
		pos += 8

		// Read UpdatedAt timestamp
		updatedAt := binary.LittleEndian.Uint64(data[pos:])
		schema.UpdatedAt = time.Unix(0, int64(updatedAt))
		pos += 8
	} else {
		// Use current time if timestamps aren't available
		now := time.Now()
		schema.CreatedAt = now
		schema.UpdatedAt = now
	}

	return schema, nil
}

func (s *Snapshotter) deserializeRow(data []byte) (storage.Row, error) {
	if len(data) < 2 {
		return nil, fmt.Errorf("invalid row data: too short")
	}

	// Read column count
	colCount := int(uint16(data[0])<<8 | uint16(data[1]))
	pos := 2

	// Create row with pre-allocated capacity
	row := make(storage.Row, colCount)

	// Read each column
	for i := 0; i < colCount; i++ {
		if pos >= len(data) {
			return nil, fmt.Errorf("unexpected end of data at column %d", i)
		}

		// Read type marker
		marker := data[pos]
		pos++

		if marker == binser.TypeNull {
			// NULL value
			row[i] = storage.StaticNullUnknown
			continue
		}

		if marker == binser.TypeUint8 {
			// Our custom format - read column type
			if pos >= len(data) {
				return nil, fmt.Errorf("unexpected end of data while reading column type for column %d", i)
			}
			colType := storage.DataType(data[pos])
			pos++

			// Bounds checking helper function
			ensureSpace := func(needed int, description string) error {
				if pos+needed > len(data) {
					return fmt.Errorf("unexpected end of data while reading %s for column %d", description, i)
				}
				return nil
			}

			// Read value based on type
			switch colType {
			case storage.TypeInteger:
				if err := ensureSpace(9, "integer"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeInt64 {
					return nil, fmt.Errorf("invalid integer format for column %d", i)
				}
				pos++
				val := int64(binary.LittleEndian.Uint64(data[pos:]))
				row[i] = storage.NewIntegerValue(val)
				pos += 8

			case storage.TypeFloat:
				if err := ensureSpace(9, "float"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeFloat64 {
					return nil, fmt.Errorf("invalid float format for column %d", i)
				}
				pos++
				bits := binary.LittleEndian.Uint64(data[pos:])
				val := math.Float64frombits(bits)
				row[i] = storage.NewFloatValue(val)
				pos += 8

			case storage.TypeString:
				if err := ensureSpace(1, "string marker"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeString {
					return nil, fmt.Errorf("invalid string format for column %d", i)
				}
				pos++
				if err := ensureSpace(4, "string length"); err != nil {
					return nil, err
				}
				length := binary.LittleEndian.Uint32(data[pos:])
				pos += 4
				if err := ensureSpace(int(length), "string data"); err != nil {
					return nil, err
				}
				val := string(data[pos : pos+int(length)])
				row[i] = storage.NewStringValue(val)
				pos += int(length)

			case storage.TypeBoolean:
				if err := ensureSpace(1, "boolean marker"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeBool {
					return nil, fmt.Errorf("invalid boolean format for column %d", i)
				}
				pos++
				if err := ensureSpace(1, "boolean value"); err != nil {
					return nil, err
				}
				val := data[pos] != 0
				row[i] = storage.NewBooleanValue(val)
				pos++

			case storage.TypeTimestamp, storage.TypeDate, storage.TypeTime:
				if err := ensureSpace(1, "time marker"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeTime {
					return nil, fmt.Errorf("invalid time format for column %d", i)
				}
				pos++
				if err := ensureSpace(8, "time value"); err != nil {
					return nil, err
				}
				nanos := int64(binary.LittleEndian.Uint64(data[pos:]))
				val := time.Unix(0, nanos)
				pos += 8

				// Create appropriate time-based value
				switch colType {
				case storage.TypeTimestamp:
					row[i] = storage.NewTimestampValue(val)
				case storage.TypeDate:
					row[i] = storage.NewDateValue(val)
				case storage.TypeTime:
					row[i] = storage.NewTimeValue(val)
				}

			case storage.TypeJSON:
				if err := ensureSpace(1, "JSON marker"); err != nil {
					return nil, err
				}
				if data[pos] != binser.TypeString {
					return nil, fmt.Errorf("invalid JSON format for column %d", i)
				}
				pos++
				if err := ensureSpace(4, "JSON length"); err != nil {
					return nil, err
				}
				length := binary.LittleEndian.Uint32(data[pos:])
				pos += 4
				if err := ensureSpace(int(length), "JSON data"); err != nil {
					return nil, err
				}
				val := string(data[pos : pos+int(length)])
				row[i] = storage.NewJSONValue(val)
				pos += int(length)

			default:
				return nil, fmt.Errorf("unsupported column type: %d for column %d", colType, i)
			}
		} else {
			// Legacy format - return a clear error
			return nil, fmt.Errorf("legacy format not supported in deserializeRow for column %d", i)
		}
	}

	return row, nil
}

// verifySnapshotFile checks if a snapshot file is valid
func (s *Snapshotter) verifySnapshotFile(tableName, snapshotFile string) error {
	binPath := filepath.Join(s.snapshotDir, tableName, snapshotFile)
	metaPath := strings.TrimSuffix(binPath, ".bin") + ".meta"

	// Check files exist
	if _, err := os.Stat(binPath); err != nil {
		return fmt.Errorf("snapshot file not found: %w", err)
	}

	if _, err := os.Stat(metaPath); err != nil {
		return fmt.Errorf("metadata file not found: %w", err)
	}

	// Open and check header with proper error handling
	file, err := os.Open(binPath)
	if err != nil {
		return fmt.Errorf("failed to open snapshot file: %w", err)
	}
	defer file.Close()

	header := make([]byte, SchemaHeaderSize)
	n, err := io.ReadFull(file, header)
	if err != nil {
		return fmt.Errorf("failed to read header (%d bytes read): %w", n, err)
	}

	// Verify magic bytes
	if header[0] != 'S' || header[1] != 'T' || header[2] != 'L' || header[3] != 'P' {
		return fmt.Errorf("invalid magic bytes in snapshot file")
	}

	// Verify version
	version := header[4]
	if version != SchemaVersion {
		return fmt.Errorf("unsupported schema version: %d", version)
	}

	return nil
}
